# Environmental-Context
Playing around with variety of LLM's by 1V1ing if environmental context really effects responses

(Readme will be updated)

**All the files will be cleaned up and more structured flow will be curated on them **

Basic Context
vectorize.py - how to document load, text split , vectorize and store the embeddings
query1.py - run a simple query which can be infered from the document (even though poor similarity score) and do a 1V1 response check, Did with a medical article ðŸ™‚ TY Harvard School of Medicine
query2.py - a more broader reasearch intese query and llm needs to infer more on the reasearch document 
docker-compose- for spinning and setting up a PG vector db composed by timescale
example.env file contains all the requirements 
requirements file - has all the stuff you need to run this

Objectives
	â€¢	Evaluate different LLMs (e.g., Gemini, Medically Trained Models) on retrieval tasks with varying levels of similarity.
	â€¢	Use a vector database (PGVector with TimescaleDB) to store embeddings and conduct similarity searches.
	â€¢	Compare similarity scores and reasoning depth of responses generated by different models.
	â€¢	Analyze retrieval effectiveness in medical or general knowledge-based queries.

